{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b4ed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Authors</th>\n",
       "      <th>Publication Year</th>\n",
       "      <th>Article Title</th>\n",
       "      <th>Abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daios, A; Kladovasilakis, N; Kelemis, A; Kosta...</td>\n",
       "      <td>2025</td>\n",
       "      <td>AI Applications in Supply Chain Management: A ...</td>\n",
       "      <td>The advent of Industry 4.0 and the integration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El Haoud, N; Bachiri, Z</td>\n",
       "      <td>2019</td>\n",
       "      <td>Stochastic Artificial Intelligence benefits an...</td>\n",
       "      <td>Supply chain management (SCM) includes several...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wamba, SF; Queiroz, MM; Guthrie, C; Braganza, A</td>\n",
       "      <td>2022</td>\n",
       "      <td>Industry experiences of artificial intelligenc...</td>\n",
       "      <td>This editorial aims to present the papers acce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hangl, J; Behrens, VJ; Krause, S</td>\n",
       "      <td>2022</td>\n",
       "      <td>Barriers, Drivers, and Social Considerations f...</td>\n",
       "      <td>Background: The number of publications in supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Shrivastav, M</td>\n",
       "      <td>2022</td>\n",
       "      <td>Barriers Related to AI Implementation in Suppl...</td>\n",
       "      <td>The primary objective of this paper is to offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Santos, CR; Azevedo, G; Marques, RP</td>\n",
       "      <td>2024</td>\n",
       "      <td>A Guide to Identifying Artificial Intelligence...</td>\n",
       "      <td>Artificial Intelligence (AI) is a topic that h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Qasim, A; El Refae, GA; Issa, H; Eletter, S</td>\n",
       "      <td>2021</td>\n",
       "      <td>The Impact of Drone Technology on The Accounti...</td>\n",
       "      <td>The accounting profession has gone through rad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Kane, S; Moody, V; Harradon, M</td>\n",
       "      <td>2021</td>\n",
       "      <td>Towards Incorporating AI into the Mission Plan...</td>\n",
       "      <td>While there are numerous powerful tools to sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Young, A; Tan, KV; Tariq, F; Fin, MX; Blueston...</td>\n",
       "      <td>2024</td>\n",
       "      <td>Rogue AI: Cautionary Cases in Neuroradiology a...</td>\n",
       "      <td>Introduction In recent years, artificial intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Ji, H; Suo, LL; Chen, H</td>\n",
       "      <td>2024</td>\n",
       "      <td>AI performance assessment in blended learning:...</td>\n",
       "      <td>Introduction: Blended learning combines the st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Authors  Publication Year  \\\n",
       "0    Daios, A; Kladovasilakis, N; Kelemis, A; Kosta...              2025   \n",
       "1                              El Haoud, N; Bachiri, Z              2019   \n",
       "2      Wamba, SF; Queiroz, MM; Guthrie, C; Braganza, A              2022   \n",
       "3                     Hangl, J; Behrens, VJ; Krause, S              2022   \n",
       "4                                        Shrivastav, M              2022   \n",
       "..                                                 ...               ...   \n",
       "995                Santos, CR; Azevedo, G; Marques, RP              2024   \n",
       "996        Qasim, A; El Refae, GA; Issa, H; Eletter, S              2021   \n",
       "997                     Kane, S; Moody, V; Harradon, M              2021   \n",
       "998  Young, A; Tan, KV; Tariq, F; Fin, MX; Blueston...              2024   \n",
       "999                            Ji, H; Suo, LL; Chen, H              2024   \n",
       "\n",
       "                                         Article Title  \\\n",
       "0    AI Applications in Supply Chain Management: A ...   \n",
       "1    Stochastic Artificial Intelligence benefits an...   \n",
       "2    Industry experiences of artificial intelligenc...   \n",
       "3    Barriers, Drivers, and Social Considerations f...   \n",
       "4    Barriers Related to AI Implementation in Suppl...   \n",
       "..                                                 ...   \n",
       "995  A Guide to Identifying Artificial Intelligence...   \n",
       "996  The Impact of Drone Technology on The Accounti...   \n",
       "997  Towards Incorporating AI into the Mission Plan...   \n",
       "998  Rogue AI: Cautionary Cases in Neuroradiology a...   \n",
       "999  AI performance assessment in blended learning:...   \n",
       "\n",
       "                                              Abstract  \n",
       "0    The advent of Industry 4.0 and the integration...  \n",
       "1    Supply chain management (SCM) includes several...  \n",
       "2    This editorial aims to present the papers acce...  \n",
       "3    Background: The number of publications in supp...  \n",
       "4    The primary objective of this paper is to offe...  \n",
       "..                                                 ...  \n",
       "995  Artificial Intelligence (AI) is a topic that h...  \n",
       "996  The accounting profession has gone through rad...  \n",
       "997  While there are numerous powerful tools to sup...  \n",
       "998  Introduction In recent years, artificial intel...  \n",
       "999  Introduction: Blended learning combines the st...  \n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This script loads the data from the CSV files generated by the querying the journal database (Web of Science).\n",
    "\n",
    "# The CSV files are saved in the Data directory.\n",
    "directory = './Data'\n",
    "\n",
    "# Weird encoding issue with the first query. Might have saved it using a Mac filesystem.\n",
    "# The rest of the queries are saved using a Windows filesystem.\n",
    "combined_df = pd.concat([\n",
    "    pd.read_csv(f'{directory}/Query1.csv', sep=',', encoding='utf-8-sig', low_memory=False).rename(columns=lambda x: x.strip()),\n",
    "    pd.read_csv(f'{directory}/Query2.csv', sep=',', encoding='ISO-8859-1', low_memory=False).rename(columns=lambda x: x.strip()),\n",
    "    pd.read_csv(f'{directory}/Query3.csv', sep=',', encoding='ISO-8859-1', low_memory=False).rename(columns=lambda x: x.strip()),\n",
    "    pd.read_csv(f'{directory}/Query4.csv', sep=',', encoding='ISO-8859-1', low_memory=False).rename(columns=lambda x: x.strip()),\n",
    "    pd.read_csv(f'{directory}/Query5.csv', sep=',', encoding='ISO-8859-1', low_memory=False).rename(columns=lambda x: x.strip())\n",
    "], ignore_index=True)\n",
    "\n",
    "# Defines the columns to keep from the combined dataframe.\n",
    "columns = ['Authors', 'Publication Year', 'Article Title', 'Abstract']\n",
    "\n",
    "# Selects the columns from the combined dataframe.\n",
    "clean_df = combined_df[columns]\n",
    "\n",
    "# Shows the dataframe and confirms that the data is loaded and the correct columns are selected.\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55308f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\etien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\etien\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in all cleaned abstracts: 119920\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Function to clean abstract text\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''  # handle NaN or other non-string entries\n",
    "\n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stopwords and non-alphanumeric characters\n",
    "    filtered_words = [\n",
    "        re.sub(r\"(?<!\\d)\\.(?!\\d)|[^a-zA-Z0-9'.]\", '', word)\n",
    "        for word in words if word.lower() not in stop_words\n",
    "    ]\n",
    "\n",
    "    # Remove empty strings from list (could result from punctuation-only words)\n",
    "    filtered_words = [word for word in filtered_words if word]\n",
    "\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Example: assuming your DataFrame is called `clean_df`\n",
    "clean_df = clean_df.copy()\n",
    "clean_df['Cleaned Abstract'] = clean_df['Abstract'].apply(clean_text)\n",
    "\n",
    "\n",
    "# Count total number of words across all cleaned abstracts\n",
    "total_words = clean_df['Cleaned Abstract'].apply(lambda x: len(x.split())).sum()\n",
    "\n",
    "print(f\"Total number of words in all cleaned abstracts: {total_words}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4dfaef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "partitions = []\n",
    "words_per_partition = 100\n",
    "\n",
    "# Iterate through each row in the dataframe\n",
    "for _, row in clean_df.iterrows():\n",
    "    cleaned_text = row['Cleaned Abstract']\n",
    "    if not cleaned_text:\n",
    "        continue\n",
    "\n",
    "    words = cleaned_text.split()\n",
    "\n",
    "    for i in range(0, len(words), words_per_partition):\n",
    "        partition_text = ' '.join(words[i:i+words_per_partition])\n",
    "        partitions.append({\n",
    "            'Title': row['Article Title'],\n",
    "            'Year': row['Publication Year'],\n",
    "            'Authors': row['Authors'],\n",
    "            'Partitioned Abstract': partition_text\n",
    "        })\n",
    "\n",
    "# Create the new DataFrame\n",
    "partition_df = pd.DataFrame(partitions)\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "partition_df.head()\n",
    "\n",
    "# Save the partitioned DataFrame to a CSV file\n",
    "partition_df.to_csv(f'{directory}/Partitioned_Abstracts.csv', index=False, encoding='utf-8-sig')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
